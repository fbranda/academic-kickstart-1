@incollection{Manco2017a,
 abstract = {The soaring amount of data coming from a variety of sources including social networks and mobile devices opens up new perspectives while at the same time posing new challenges. On one hand, AI-systems like Neural Networks paved the way toward new applications ranging from self-driving cars to text understanding. On the other hand, the management and analysis of data that fed these applications raises concerns about the privacy of data contributors. One robust (from the mathematical point of view) privacy definition is that of Differential Privacy (DP). The peculiarity of DP-based algorithms is that they do not work on anonymized versions of the data; they add a calibrated amount of noise before releasing the results, instead. The goals of this paper are: to give an overview on recent research results marrying DP and neural networks; to present a blueprint for differentially private neural networks; and, to discuss our findings and point out new research challenges.},
 author = {Giuseppe Manco and Giuseppe Pirr√≤},
 booktitle = {Personal Analytics and Privacy. An Individual and Collective Perspective},
 doi = {10.1007/978-3-319-71970-2_4},
 pages = {23--35},
 publisher = {Springer International Publishing},
 title = {Differential Privacy and Neural Networks: A Preliminary Analysis},
 year = {2017}
}

